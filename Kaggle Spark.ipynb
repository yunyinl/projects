{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x10bbbab38>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x110edf860>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "```\n",
    "In this step, we load the four dataset, and join the attributes, description, and traning data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\",encoding ='latin1')\n",
    "train_data = pd.read_csv('train.csv',encoding ='latin1')\n",
    "attributes = pd.read_csv(\"attributes.csv\",encoding ='latin1')\n",
    "product_description = pd.read_csv(\"product_descriptions.csv\",encoding ='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def merge(attr):\n",
    "    return \" \".join(list(attr[\"value\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_without1 = train_data[train_data[\"product_title\"].str.contains(\"without\")]\n",
    "df_without2 = test_data[test_data[\"product_title\"].str.contains(\"without\")]\n",
    "df_without3 = train_data[train_data[\"search_term\"].str.contains(\"without\")]\n",
    "df_without4 = test_data[test_data[\"search_term\"].str.contains(\"without\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00102609799236\n",
      "0.0011338208563\n",
      "0.000337532234328\n",
      "0.000269957346739\n"
     ]
    }
   ],
   "source": [
    "print(df_without1.size/train_data.size)\n",
    "print(df_without2.size/test_data.size)\n",
    "print(df_without3.size/train_data.size)\n",
    "print(df_without4.size/test_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "attributes.dropna(how=\"all\", inplace=True)\n",
    "attributes[\"product_uid\"] = attributes[\"product_uid\"].astype(int)\n",
    "attributes[\"value\"] = attributes[\"value\"].astype(str)\n",
    "product_attributes = attributes.groupby(\"product_uid\").apply(merge)\n",
    "product_attributes = product_attributes.reset_index(name=\"product_attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, product_attributes, how=\"left\", on=\"product_uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, product_description, how=\"left\", on=\"product_uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "      <th>product_attributes</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Versatile connector for various 90Â° connectio...</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Versatile connector for various 90Â° connectio...</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                      product_title    search_term  \\\n",
       "0   2       100001  Simpson Strong-Tie 12-Gauge Angle  angle bracket   \n",
       "1   3       100001  Simpson Strong-Tie 12-Gauge Angle      l bracket   \n",
       "\n",
       "   relevance                                 product_attributes  \\\n",
       "0        3.0  Versatile connector for various 90Â° connectio...   \n",
       "1        2.5  Versatile connector for various 90Â° connectio...   \n",
       "\n",
       "                                 product_description  \n",
       "0  Not only do angles make joints stronger, they ...  \n",
       "1  Not only do angles make joints stronger, they ...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+\n",
      "| id|   uid|               title|         term|score|          attributes|         description|\n",
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+\n",
      "|  2|100001|Simpson Strong-Ti...|angle bracket|  3.0|Versatile connect...|Not only do angle...|\n",
      "|  3|100001|Simpson Strong-Ti...|    l bracket|  2.5|Versatile connect...|Not only do angle...|\n",
      "|  9|100002|BEHR Premium Text...|    deck over|  3.0|Brush,Roller,Spra...|BEHR Premium Text...|\n",
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType,StringType,IntegerType\n",
    "\n",
    "sql_sc = SQLContext(sc)\n",
    "\n",
    "trainSchema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"uid\", IntegerType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"term\", StringType()),\n",
    "    StructField(\"score\", DoubleType()),\n",
    "    StructField(\"attributes\", StringType()),\n",
    "    StructField(\"description\", StringType())\n",
    "])\n",
    "\n",
    "rawTrain = sql_sc.createDataFrame(train_data, trainSchema)\n",
    "rawTrain.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the spell mistakes in search terms\n",
    "```\n",
    "In this step we replace the words that is spelled wrong in search terms, with correct terms. The spell check dictionary is shared by a kaggle team: www.kaggle.com/steubk/fixing-typos\n",
    "We learned to use broadcast variable in Spark.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from spellCheckDict import spell_check_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bc_search_term = sc.broadcast(spell_check_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+------------------+-----+--------------------+--------------------+\n",
      "| id|   uid|               title|              term|score|          attributes|         description|\n",
      "+---+------+--------------------+------------------+-----+--------------------+--------------------+\n",
      "|  2|100001|Simpson Strong-Ti...|     angle bracket|  3.0|Versatile connect...|Not only do angle...|\n",
      "|  3|100001|Simpson Strong-Ti...|         l bracket|  2.5|Versatile connect...|Not only do angle...|\n",
      "|  9|100002|BEHR Premium Text...|         deck over|  3.0|Brush,Roller,Spra...|BEHR Premium Text...|\n",
      "| 16|100005|Delta Vero 1-Hand...|  rain shower head| 2.33|Combo Tub and Sho...|Update your bathr...|\n",
      "| 17|100005|Delta Vero 1-Hand...|shower only faucet| 2.67|Combo Tub and Sho...|Update your bathr...|\n",
      "+---+------+--------------------+------------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType,StringType,IntegerType\n",
    "def spellCheck(val):\n",
    "    if val in bc_search_term.value:\n",
    "        return bc_search_term.value.get(val)\n",
    "    else:\n",
    "        return val\n",
    "scUDF =udf(spellCheck, StringType())\n",
    "\n",
    "rawTrain = rawTrain.withColumn(\"term\", scUDF(\"term\")) #\n",
    "rawTrain.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with, without\n",
    "```\n",
    "There is a situation, where in product_title it says the product is \"without ABC\" while in the search term the user is searching for \"ABC\". When using our machine learning algorithm, the algorithm will think the product matches users need because the search words appear in the title. This is apparently wrong.\n",
    "\n",
    "To deal with this, we could have seperate out the words appears after the \"without\" and give it negative weight. Yet for computation purpose we decide to remove the \"without ABC\" from the title and search words.\n",
    "\n",
    "Example data：\n",
    "\n",
    "\"id\",\"product_uid\",\"product_title\",\"search_term\",\"relevance\"\n",
    "\n",
    "22888,104429,\"Ryobi One+ 18-Volt Lithium-ion Shaft Cordless Electric String Trimmer and Edger without Battery and Charger\",\"18v battery charger\",2\n",
    "2050,100368,\"Niza Pro 2-piece 1.28 GPF Single Flush Round Toilet without Toilet Seat in White\",\"buikids toilet seat\",2\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_without(sentence):\n",
    "    sentenceL = sentence.split()\n",
    "    #print(sentenceL)\n",
    "    for i in range(len(sentenceL)):\n",
    "        #print(sentenceL[i])\n",
    "        if sentenceL[i] == \"without\":\n",
    "            sentenceL = sentenceL[:i]\n",
    "            return \" \".join(sentenceL)\n",
    "    return sentence\n",
    "withoutUDF = udf(find_without,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawTrain1 = rawTrain.withColumn(\"term\", withoutUDF(rawTrain[\"term\"])) \n",
    "#rawTrain = rawTrain.withColumn(\"title\", withoutUDF(\"title\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+\n",
      "| id|   uid|               title|         term|score|          attributes|         description|\n",
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+\n",
      "|  2|100001|Simpson Strong-Ti...|angle bracket|  3.0|Versatile connect...|Not only do angle...|\n",
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawTrain1.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "```\n",
    "We tokenize the sentences, remove stop words, stemmed the words, and generated 1-2-3-4-5 grams and compare ngram match. We also believe matching longer continuous words refers a higher correlation between product and search term. So we also use the length of words match and the length of the search term as our features.\n",
    "We picked 5 as maximum n because we believe matching 5 continuous words should already mean that the two sentences are very similar, thus will not introduce more than 5 grams, which will demand more computational power.  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType,StringType,IntegerType,ArrayType\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "sb = SnowballStemmer(\"english\") \n",
    "\n",
    "def stem_word(text):\n",
    "    return [sb.stem(word) for word in text]\n",
    "stemUDF = udf(stem_word,ArrayType(StringType())) #不写type就默认string了，虽然是\"[]\"\n",
    "\n",
    "#process title\n",
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"title_1\")\n",
    "temp = tokenizer.transform(rawTrain1)\n",
    "\n",
    "remover1 = StopWordsRemover(inputCol=\"title_1\", outputCol=\"title_2\")\n",
    "temp = remover1.transform(temp)\n",
    "\n",
    "temp = temp.withColumn(\"title_words\", stemUDF(\"title_2\"))\n",
    "\n",
    "#hashingTF = HashingTF(inputCol=\"title_words\", outputCol=\"rawFeatures\", numFeatures=16)\n",
    "#temp = hashingTF.transform(temp)\n",
    "#idf = IDF(inputCol = \"rawFeatures\", outputCol=\"title_idf\")\n",
    "#idfModel = idf.fit(temp)\n",
    "#temp = idfModel.transform(temp)\n",
    "\n",
    "ngram = NGram(n=2, inputCol=\"title_words\", outputCol=\"title_2grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=3, inputCol=\"title_words\", outputCol=\"title_3grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=4, inputCol=\"title_words\", outputCol=\"title_4grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=5, inputCol=\"title_words\", outputCol=\"title_5grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "temp=temp.drop(\"rawFeatures\").drop(\"title\").drop(\"title_1\").drop(\"title_2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#process search term\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"term\", outputCol=\"term_1\")\n",
    "temp = tokenizer.transform(temp)\n",
    "\n",
    "remover1 = StopWordsRemover(inputCol=\"term_1\", outputCol=\"term_2\")\n",
    "temp = remover1.transform(temp)\n",
    "\n",
    "temp = temp.withColumn(\"term_words\", stemUDF(\"term_2\"))\n",
    "\n",
    "#hashingTF = HashingTF(inputCol=\"term_words\", outputCol=\"rawFeatures\", numFeatures=16)\n",
    "#temp = hashingTF.transform(temp)\n",
    "#idf = IDF(inputCol = \"rawFeatures\", outputCol=\"term_idf\")\n",
    "#idfModel = idf.fit(temp)\n",
    "#temp = idfModel.transform(temp)\n",
    "\n",
    "ngram = NGram(n=2, inputCol=\"term_words\", outputCol=\"term_2grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=3, inputCol=\"term_words\", outputCol=\"term_3grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=4, inputCol=\"term_words\", outputCol=\"term_4grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=5, inputCol=\"term_words\", outputCol=\"term_5grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "temp=temp.drop(\"rawFeatures\").drop(\"term\").drop(\"term_1\").drop(\"term_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#process description\n",
    "tokenizer = Tokenizer(inputCol=\"description\", outputCol=\"description_1\")\n",
    "temp = tokenizer.transform(temp)\n",
    "\n",
    "remover1 = StopWordsRemover(inputCol=\"description_1\", outputCol=\"description_2\")\n",
    "temp = remover1.transform(temp)\n",
    "\n",
    "temp = temp.withColumn(\"description_words\", stemUDF(\"description_2\"))\n",
    "\n",
    "#hashingTF = HashingTF(inputCol=\"description_words\", outputCol=\"rawFeatures\", numFeatures=16)\n",
    "#temp = hashingTF.transform(temp)\n",
    "#idf = IDF(inputCol = \"rawFeatures\", outputCol=\"description_idf\")\n",
    "#idfModel = idf.fit(temp)\n",
    "#temp = idfModel.transform(temp)\n",
    "\n",
    "ngram = NGram(n=2, inputCol=\"description_words\", outputCol=\"description_2grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=3, inputCol=\"description_words\", outputCol=\"description_3grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=4, inputCol=\"description_words\", outputCol=\"description_4grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=5, inputCol=\"description_words\", outputCol=\"description_5grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "temp=temp.drop(\"rawFeatures\").drop(\"description\").drop(\"description_1\").drop(\"description_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#process attributes\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"attributes\", outputCol=\"attributes_1\")\n",
    "temp = tokenizer.transform(temp)\n",
    "\n",
    "remover1 = StopWordsRemover(inputCol=\"attributes_1\", outputCol=\"attributes_2\")\n",
    "temp = remover1.transform(temp)\n",
    "\n",
    "temp = temp.withColumn(\"attributes_words\", stemUDF(\"attributes_2\"))\n",
    "\n",
    "#hashingTF = HashingTF(inputCol=\"attributes_words\", outputCol=\"rawFeatures\", numFeatures=16)\n",
    "#temp = hashingTF.transform(temp)\n",
    "#idf = IDF(inputCol = \"rawFeatures\", outputCol=\"attributes_idf\")\n",
    "#idfModel = idf.fit(temp)\n",
    "#temp = idfModel.transform(temp)\n",
    "\n",
    "ngram = NGram(n=2, inputCol=\"attributes_words\", outputCol=\"attributes_2grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=3, inputCol=\"attributes_words\", outputCol=\"attributes_3grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=4, inputCol=\"attributes_words\", outputCol=\"attributes_4grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "ngram = NGram(n=5, inputCol=\"attributes_words\", outputCol=\"attributes_5grams\")\n",
    "temp = ngram.transform(temp)\n",
    "\n",
    "temp=temp.drop(\"rawFeatures\").drop(\"attributes\").drop(\"attributes_1\").drop(\"attributes_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length  #string\n",
    "from pyspark.sql.functions import size  #array\n",
    "\n",
    "temp = temp.withColumn(\"search_term_length\",size(\"term_words\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|    id|score|\n",
      "+------+-----+\n",
      "| 11752|  1.0|\n",
      "| 16601| 1.67|\n",
      "| 27425|  1.0|\n",
      "| 27953| 1.67|\n",
      "| 28230|  2.0|\n",
      "| 55100| 1.67|\n",
      "| 55372|  1.0|\n",
      "| 55762| 1.67|\n",
      "| 55898| 1.33|\n",
      "| 68566|  1.0|\n",
      "| 69261|  1.0|\n",
      "| 70056| 2.33|\n",
      "| 76500| 1.67|\n",
      "| 81246| 1.67|\n",
      "| 95573| 2.33|\n",
      "|105334| 1.67|\n",
      "|108561| 1.67|\n",
      "|114426| 1.67|\n",
      "|119352|  2.0|\n",
      "|155970|  1.0|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This is the step verifying the relevance score when the search term length is zero after preprocessing.\n",
    "#We can see that these scores are very low, so the result is verified. \n",
    "temp.where(temp[\"search_term_length\"]==0).select(\"id\",\"score\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Example rows with \"zero\" search term length after preprocessing the text:\n",
    "\n",
    "\"id\",\"product_uid\",\"product_title\",\"search_term\",\"relevance\"\n",
    "\n",
    "16601,102930,\"Hampton Bay Adonia 52 in. Oil Rubbed Bronze Ceiling Fan\",\"or\",1.67\n",
    "27425,105706,\"Hampton Bay Waterton II 52 in. Oil Rubbed Bronze Ceiling Fan\",\"or\",1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'uid',\n",
       " 'score',\n",
       " 'title_words',\n",
       " 'title_2grams',\n",
       " 'title_3grams',\n",
       " 'title_4grams',\n",
       " 'title_5grams',\n",
       " 'term_words',\n",
       " 'term_2grams',\n",
       " 'term_3grams',\n",
       " 'term_4grams',\n",
       " 'term_5grams',\n",
       " 'description_words',\n",
       " 'description_2grams',\n",
       " 'description_3grams',\n",
       " 'description_4grams',\n",
       " 'description_5grams',\n",
       " 'attributes_words',\n",
       " 'attributes_2grams',\n",
       " 'attributes_3grams',\n",
       " 'attributes_4grams',\n",
       " 'attributes_5grams',\n",
       " 'search_term_length']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+--------------------+--------------------+--------------------+--------------------+------------+---------------+--------------+-----------+-----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
      "| id|   uid|score|         title_words|        title_2grams|        title_3grams|        title_4grams|title_5grams|     term_words|   term_2grams|term_3grams|term_4grams|term_5grams|   description_words|  description_2grams|  description_3grams|  description_4grams|  description_5grams|    attributes_words|   attributes_2grams|   attributes_3grams|   attributes_4grams|   attributes_5grams|search_term_length|\n",
      "+---+------+-----+--------------------+--------------------+--------------------+--------------------+------------+---------------+--------------+-----------+-----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
      "|  2|100001|  3.0|[simpson, strong-...|[simpson strong-t...|[simpson strong-t...|[simpson strong-t...|          []|[angl, bracket]|[angl bracket]|         []|         []|         []|[angl, make, join...|[angl make, make ...|[angl make joint,...|[angl make joint ...|[angl make joint ...|[versatil, connec...|[versatil connect...|[versatil connect...|[versatil connect...|[versatil connect...|                 2|\n",
      "+---+------+-----+--------------------+--------------------+--------------------+--------------------+------------+---------------+--------------+-----------+-----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType,StringType,IntegerType\n",
    "\n",
    "def compareTerms(a,b):\n",
    "    match = 0\n",
    "    for word in a:\n",
    "        match += b.count(a)\n",
    "    return match    \n",
    "compareudf = udf(compareTerms, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "temp=temp.withColumn(\"term_title_1gram\",compareudf(\"term_words\",\"title_words\"))\n",
    "temp=temp.withColumn(\"term_title_2gram\",compareudf(\"term_2grams\",\"title_2grams\"))\n",
    "temp=temp.withColumn(\"term_title_3gram\",compareudf(\"term_3grams\",\"title_3grams\"))\n",
    "temp=temp.withColumn(\"term_title_4gram\",compareudf(\"term_4grams\",\"title_4grams\"))\n",
    "temp=temp.withColumn(\"term_title_5gram\",compareudf(\"term_5grams\",\"title_5grams\"))\n",
    "\n",
    "temp=temp.withColumn(\"term_description_1gram\",compareudf(\"term_words\",\"description_words\"))\n",
    "temp=temp.withColumn(\"term_description_2gram\",compareudf(\"term_2grams\",\"description_2grams\"))\n",
    "temp=temp.withColumn(\"term_description_3gram\",compareudf(\"term_3grams\",\"description_3grams\"))\n",
    "temp=temp.withColumn(\"term_description_4gram\",compareudf(\"term_4grams\",\"description_4grams\"))\n",
    "temp=temp.withColumn(\"term_description_5gram\",compareudf(\"term_5grams\",\"description_5grams\"))\n",
    "\n",
    "temp=temp.withColumn(\"term_attributes_1gram\",compareudf(\"term_words\",\"attributes_words\"))\n",
    "temp=temp.withColumn(\"term_attributes_1gram\",compareudf(\"term_2grams\",\"attributes_2grams\"))\n",
    "temp=temp.withColumn(\"term_attributes_3gram\",compareudf(\"term_3grams\",\"attributes_3grams\"))\n",
    "temp=temp.withColumn(\"term_attributes_4gram\",compareudf(\"term_4grams\",\"attributes_4grams\"))\n",
    "temp=temp.withColumn(\"term_attributes_5gram\",compareudf(\"term_5grams\",\"attributes_5grams\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, term_description_5gram: string]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.describe(\"term_description_5gram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=2, uid=100001, score=3.0, title_words=['simpson', 'strong-ti', '12-gaug', 'angl'], title_2grams=['simpson strong-ti', 'strong-ti 12-gaug', '12-gaug angl'], title_3grams=['simpson strong-ti 12-gaug', 'strong-ti 12-gaug angl'], title_4grams=['simpson strong-ti 12-gaug angl'], title_5grams=[], term_words=['angl', 'bracket'], term_2grams=['angl bracket'], term_3grams=[], term_4grams=[], term_5grams=[], description_words=['angl', 'make', 'joint', 'stronger,', 'also', 'provid', 'consistent,', 'straight', 'corners.', 'simpson', 'strong-ti', 'offer', 'wide', 'varieti', 'angl', 'various', 'size', 'thick', 'handl', 'light-duti', 'job', 'project', 'structur', 'connect', 'needed.', 'bent', '(skewed)', 'match', 'project.', 'outdoor', 'project', 'moistur', 'present,', 'use', 'zmax', 'zinc-coat', 'connectors,', 'provid', 'extra', 'resist', 'corros', '(look', '\"z\"', 'end', 'model', 'number).versatil', 'connector', 'various', '90', 'connect', 'home', 'repair', 'projectsstrong', 'angl', 'nail', 'screw', 'fasten', 'alonehelp', 'ensur', 'joint', 'consist', 'straight', 'strongdimensions:', '3', 'in.', 'x', '3', 'in.', 'x', '1-1/2', 'in.mad', '12-gaug', 'steelgalvan', 'extra', 'corros', 'resistanceinstal', '10d', 'common', 'nail', '#9', 'x', '1-1/2', 'in.', 'strong-driv', 'sd', 'screw'], description_2grams=['angl make', 'make joint', 'joint stronger,', 'stronger, also', 'also provid', 'provid consistent,', 'consistent, straight', 'straight corners.', 'corners. simpson', 'simpson strong-ti', 'strong-ti offer', 'offer wide', 'wide varieti', 'varieti angl', 'angl various', 'various size', 'size thick', 'thick handl', 'handl light-duti', 'light-duti job', 'job project', 'project structur', 'structur connect', 'connect needed.', 'needed. bent', 'bent (skewed)', '(skewed) match', 'match project.', 'project. outdoor', 'outdoor project', 'project moistur', 'moistur present,', 'present, use', 'use zmax', 'zmax zinc-coat', 'zinc-coat connectors,', 'connectors, provid', 'provid extra', 'extra resist', 'resist corros', 'corros (look', '(look \"z\"', '\"z\" end', 'end model', 'model number).versatil', 'number).versatil connector', 'connector various', 'various 90', '90 connect', 'connect home', 'home repair', 'repair projectsstrong', 'projectsstrong angl', 'angl nail', 'nail screw', 'screw fasten', 'fasten alonehelp', 'alonehelp ensur', 'ensur joint', 'joint consist', 'consist straight', 'straight strongdimensions:', 'strongdimensions: 3', '3 in.', 'in. x', 'x 3', '3 in.', 'in. x', 'x 1-1/2', '1-1/2 in.mad', 'in.mad 12-gaug', '12-gaug steelgalvan', 'steelgalvan extra', 'extra corros', 'corros resistanceinstal', 'resistanceinstal 10d', '10d common', 'common nail', 'nail #9', '#9 x', 'x 1-1/2', '1-1/2 in.', 'in. strong-driv', 'strong-driv sd', 'sd screw'], description_3grams=['angl make joint', 'make joint stronger,', 'joint stronger, also', 'stronger, also provid', 'also provid consistent,', 'provid consistent, straight', 'consistent, straight corners.', 'straight corners. simpson', 'corners. simpson strong-ti', 'simpson strong-ti offer', 'strong-ti offer wide', 'offer wide varieti', 'wide varieti angl', 'varieti angl various', 'angl various size', 'various size thick', 'size thick handl', 'thick handl light-duti', 'handl light-duti job', 'light-duti job project', 'job project structur', 'project structur connect', 'structur connect needed.', 'connect needed. bent', 'needed. bent (skewed)', 'bent (skewed) match', '(skewed) match project.', 'match project. outdoor', 'project. outdoor project', 'outdoor project moistur', 'project moistur present,', 'moistur present, use', 'present, use zmax', 'use zmax zinc-coat', 'zmax zinc-coat connectors,', 'zinc-coat connectors, provid', 'connectors, provid extra', 'provid extra resist', 'extra resist corros', 'resist corros (look', 'corros (look \"z\"', '(look \"z\" end', '\"z\" end model', 'end model number).versatil', 'model number).versatil connector', 'number).versatil connector various', 'connector various 90', 'various 90 connect', '90 connect home', 'connect home repair', 'home repair projectsstrong', 'repair projectsstrong angl', 'projectsstrong angl nail', 'angl nail screw', 'nail screw fasten', 'screw fasten alonehelp', 'fasten alonehelp ensur', 'alonehelp ensur joint', 'ensur joint consist', 'joint consist straight', 'consist straight strongdimensions:', 'straight strongdimensions: 3', 'strongdimensions: 3 in.', '3 in. x', 'in. x 3', 'x 3 in.', '3 in. x', 'in. x 1-1/2', 'x 1-1/2 in.mad', '1-1/2 in.mad 12-gaug', 'in.mad 12-gaug steelgalvan', '12-gaug steelgalvan extra', 'steelgalvan extra corros', 'extra corros resistanceinstal', 'corros resistanceinstal 10d', 'resistanceinstal 10d common', '10d common nail', 'common nail #9', 'nail #9 x', '#9 x 1-1/2', 'x 1-1/2 in.', '1-1/2 in. strong-driv', 'in. strong-driv sd', 'strong-driv sd screw'], description_4grams=['angl make joint stronger,', 'make joint stronger, also', 'joint stronger, also provid', 'stronger, also provid consistent,', 'also provid consistent, straight', 'provid consistent, straight corners.', 'consistent, straight corners. simpson', 'straight corners. simpson strong-ti', 'corners. simpson strong-ti offer', 'simpson strong-ti offer wide', 'strong-ti offer wide varieti', 'offer wide varieti angl', 'wide varieti angl various', 'varieti angl various size', 'angl various size thick', 'various size thick handl', 'size thick handl light-duti', 'thick handl light-duti job', 'handl light-duti job project', 'light-duti job project structur', 'job project structur connect', 'project structur connect needed.', 'structur connect needed. bent', 'connect needed. bent (skewed)', 'needed. bent (skewed) match', 'bent (skewed) match project.', '(skewed) match project. outdoor', 'match project. outdoor project', 'project. outdoor project moistur', 'outdoor project moistur present,', 'project moistur present, use', 'moistur present, use zmax', 'present, use zmax zinc-coat', 'use zmax zinc-coat connectors,', 'zmax zinc-coat connectors, provid', 'zinc-coat connectors, provid extra', 'connectors, provid extra resist', 'provid extra resist corros', 'extra resist corros (look', 'resist corros (look \"z\"', 'corros (look \"z\" end', '(look \"z\" end model', '\"z\" end model number).versatil', 'end model number).versatil connector', 'model number).versatil connector various', 'number).versatil connector various 90', 'connector various 90 connect', 'various 90 connect home', '90 connect home repair', 'connect home repair projectsstrong', 'home repair projectsstrong angl', 'repair projectsstrong angl nail', 'projectsstrong angl nail screw', 'angl nail screw fasten', 'nail screw fasten alonehelp', 'screw fasten alonehelp ensur', 'fasten alonehelp ensur joint', 'alonehelp ensur joint consist', 'ensur joint consist straight', 'joint consist straight strongdimensions:', 'consist straight strongdimensions: 3', 'straight strongdimensions: 3 in.', 'strongdimensions: 3 in. x', '3 in. x 3', 'in. x 3 in.', 'x 3 in. x', '3 in. x 1-1/2', 'in. x 1-1/2 in.mad', 'x 1-1/2 in.mad 12-gaug', '1-1/2 in.mad 12-gaug steelgalvan', 'in.mad 12-gaug steelgalvan extra', '12-gaug steelgalvan extra corros', 'steelgalvan extra corros resistanceinstal', 'extra corros resistanceinstal 10d', 'corros resistanceinstal 10d common', 'resistanceinstal 10d common nail', '10d common nail #9', 'common nail #9 x', 'nail #9 x 1-1/2', '#9 x 1-1/2 in.', 'x 1-1/2 in. strong-driv', '1-1/2 in. strong-driv sd', 'in. strong-driv sd screw'], description_5grams=['angl make joint stronger, also', 'make joint stronger, also provid', 'joint stronger, also provid consistent,', 'stronger, also provid consistent, straight', 'also provid consistent, straight corners.', 'provid consistent, straight corners. simpson', 'consistent, straight corners. simpson strong-ti', 'straight corners. simpson strong-ti offer', 'corners. simpson strong-ti offer wide', 'simpson strong-ti offer wide varieti', 'strong-ti offer wide varieti angl', 'offer wide varieti angl various', 'wide varieti angl various size', 'varieti angl various size thick', 'angl various size thick handl', 'various size thick handl light-duti', 'size thick handl light-duti job', 'thick handl light-duti job project', 'handl light-duti job project structur', 'light-duti job project structur connect', 'job project structur connect needed.', 'project structur connect needed. bent', 'structur connect needed. bent (skewed)', 'connect needed. bent (skewed) match', 'needed. bent (skewed) match project.', 'bent (skewed) match project. outdoor', '(skewed) match project. outdoor project', 'match project. outdoor project moistur', 'project. outdoor project moistur present,', 'outdoor project moistur present, use', 'project moistur present, use zmax', 'moistur present, use zmax zinc-coat', 'present, use zmax zinc-coat connectors,', 'use zmax zinc-coat connectors, provid', 'zmax zinc-coat connectors, provid extra', 'zinc-coat connectors, provid extra resist', 'connectors, provid extra resist corros', 'provid extra resist corros (look', 'extra resist corros (look \"z\"', 'resist corros (look \"z\" end', 'corros (look \"z\" end model', '(look \"z\" end model number).versatil', '\"z\" end model number).versatil connector', 'end model number).versatil connector various', 'model number).versatil connector various 90', 'number).versatil connector various 90 connect', 'connector various 90 connect home', 'various 90 connect home repair', '90 connect home repair projectsstrong', 'connect home repair projectsstrong angl', 'home repair projectsstrong angl nail', 'repair projectsstrong angl nail screw', 'projectsstrong angl nail screw fasten', 'angl nail screw fasten alonehelp', 'nail screw fasten alonehelp ensur', 'screw fasten alonehelp ensur joint', 'fasten alonehelp ensur joint consist', 'alonehelp ensur joint consist straight', 'ensur joint consist straight strongdimensions:', 'joint consist straight strongdimensions: 3', 'consist straight strongdimensions: 3 in.', 'straight strongdimensions: 3 in. x', 'strongdimensions: 3 in. x 3', '3 in. x 3 in.', 'in. x 3 in. x', 'x 3 in. x 1-1/2', '3 in. x 1-1/2 in.mad', 'in. x 1-1/2 in.mad 12-gaug', 'x 1-1/2 in.mad 12-gaug steelgalvan', '1-1/2 in.mad 12-gaug steelgalvan extra', 'in.mad 12-gaug steelgalvan extra corros', '12-gaug steelgalvan extra corros resistanceinstal', 'steelgalvan extra corros resistanceinstal 10d', 'extra corros resistanceinstal 10d common', 'corros resistanceinstal 10d common nail', 'resistanceinstal 10d common nail #9', '10d common nail #9 x', 'common nail #9 x 1-1/2', 'nail #9 x 1-1/2 in.', '#9 x 1-1/2 in. strong-driv', 'x 1-1/2 in. strong-driv sd', '1-1/2 in. strong-driv sd screw'], attributes_words=['versatil', 'connector', 'various', '90â°', 'connect', 'home', 'repair', 'project', 'stronger', 'angl', 'nail', 'screw', 'fasten', 'alon', 'help', 'ensur', 'joint', 'consist', 'straight', 'strong', 'dimensions:', '3', 'in.', 'x', '3', 'in.', 'x', '1-1/2', 'in.', 'made', '12-gaug', 'steel', 'galvan', 'extra', 'corros', 'resist', 'instal', '10d', 'common', 'nail', '#9', 'x', '1-1/2', 'in.', 'strong-driv', 'sd', 'screw', '12', 'galvan', 'steel', 'simpson', 'strong-ti', '1', '1.5', '3', '0.26', '3'], attributes_2grams=['versatil connector', 'connector various', 'various 90â°', '90â° connect', 'connect home', 'home repair', 'repair project', 'project stronger', 'stronger angl', 'angl nail', 'nail screw', 'screw fasten', 'fasten alon', 'alon help', 'help ensur', 'ensur joint', 'joint consist', 'consist straight', 'straight strong', 'strong dimensions:', 'dimensions: 3', '3 in.', 'in. x', 'x 3', '3 in.', 'in. x', 'x 1-1/2', '1-1/2 in.', 'in. made', 'made 12-gaug', '12-gaug steel', 'steel galvan', 'galvan extra', 'extra corros', 'corros resist', 'resist instal', 'instal 10d', '10d common', 'common nail', 'nail #9', '#9 x', 'x 1-1/2', '1-1/2 in.', 'in. strong-driv', 'strong-driv sd', 'sd screw', 'screw 12', '12 galvan', 'galvan steel', 'steel simpson', 'simpson strong-ti', 'strong-ti 1', '1 1.5', '1.5 3', '3 0.26', '0.26 3'], attributes_3grams=['versatil connector various', 'connector various 90â°', 'various 90â° connect', '90â° connect home', 'connect home repair', 'home repair project', 'repair project stronger', 'project stronger angl', 'stronger angl nail', 'angl nail screw', 'nail screw fasten', 'screw fasten alon', 'fasten alon help', 'alon help ensur', 'help ensur joint', 'ensur joint consist', 'joint consist straight', 'consist straight strong', 'straight strong dimensions:', 'strong dimensions: 3', 'dimensions: 3 in.', '3 in. x', 'in. x 3', 'x 3 in.', '3 in. x', 'in. x 1-1/2', 'x 1-1/2 in.', '1-1/2 in. made', 'in. made 12-gaug', 'made 12-gaug steel', '12-gaug steel galvan', 'steel galvan extra', 'galvan extra corros', 'extra corros resist', 'corros resist instal', 'resist instal 10d', 'instal 10d common', '10d common nail', 'common nail #9', 'nail #9 x', '#9 x 1-1/2', 'x 1-1/2 in.', '1-1/2 in. strong-driv', 'in. strong-driv sd', 'strong-driv sd screw', 'sd screw 12', 'screw 12 galvan', '12 galvan steel', 'galvan steel simpson', 'steel simpson strong-ti', 'simpson strong-ti 1', 'strong-ti 1 1.5', '1 1.5 3', '1.5 3 0.26', '3 0.26 3'], attributes_4grams=['versatil connector various 90â°', 'connector various 90â° connect', 'various 90â° connect home', '90â° connect home repair', 'connect home repair project', 'home repair project stronger', 'repair project stronger angl', 'project stronger angl nail', 'stronger angl nail screw', 'angl nail screw fasten', 'nail screw fasten alon', 'screw fasten alon help', 'fasten alon help ensur', 'alon help ensur joint', 'help ensur joint consist', 'ensur joint consist straight', 'joint consist straight strong', 'consist straight strong dimensions:', 'straight strong dimensions: 3', 'strong dimensions: 3 in.', 'dimensions: 3 in. x', '3 in. x 3', 'in. x 3 in.', 'x 3 in. x', '3 in. x 1-1/2', 'in. x 1-1/2 in.', 'x 1-1/2 in. made', '1-1/2 in. made 12-gaug', 'in. made 12-gaug steel', 'made 12-gaug steel galvan', '12-gaug steel galvan extra', 'steel galvan extra corros', 'galvan extra corros resist', 'extra corros resist instal', 'corros resist instal 10d', 'resist instal 10d common', 'instal 10d common nail', '10d common nail #9', 'common nail #9 x', 'nail #9 x 1-1/2', '#9 x 1-1/2 in.', 'x 1-1/2 in. strong-driv', '1-1/2 in. strong-driv sd', 'in. strong-driv sd screw', 'strong-driv sd screw 12', 'sd screw 12 galvan', 'screw 12 galvan steel', '12 galvan steel simpson', 'galvan steel simpson strong-ti', 'steel simpson strong-ti 1', 'simpson strong-ti 1 1.5', 'strong-ti 1 1.5 3', '1 1.5 3 0.26', '1.5 3 0.26 3'], attributes_5grams=['versatil connector various 90â° connect', 'connector various 90â° connect home', 'various 90â° connect home repair', '90â° connect home repair project', 'connect home repair project stronger', 'home repair project stronger angl', 'repair project stronger angl nail', 'project stronger angl nail screw', 'stronger angl nail screw fasten', 'angl nail screw fasten alon', 'nail screw fasten alon help', 'screw fasten alon help ensur', 'fasten alon help ensur joint', 'alon help ensur joint consist', 'help ensur joint consist straight', 'ensur joint consist straight strong', 'joint consist straight strong dimensions:', 'consist straight strong dimensions: 3', 'straight strong dimensions: 3 in.', 'strong dimensions: 3 in. x', 'dimensions: 3 in. x 3', '3 in. x 3 in.', 'in. x 3 in. x', 'x 3 in. x 1-1/2', '3 in. x 1-1/2 in.', 'in. x 1-1/2 in. made', 'x 1-1/2 in. made 12-gaug', '1-1/2 in. made 12-gaug steel', 'in. made 12-gaug steel galvan', 'made 12-gaug steel galvan extra', '12-gaug steel galvan extra corros', 'steel galvan extra corros resist', 'galvan extra corros resist instal', 'extra corros resist instal 10d', 'corros resist instal 10d common', 'resist instal 10d common nail', 'instal 10d common nail #9', '10d common nail #9 x', 'common nail #9 x 1-1/2', 'nail #9 x 1-1/2 in.', '#9 x 1-1/2 in. strong-driv', 'x 1-1/2 in. strong-driv sd', '1-1/2 in. strong-driv sd screw', 'in. strong-driv sd screw 12', 'strong-driv sd screw 12 galvan', 'sd screw 12 galvan steel', 'screw 12 galvan steel simpson', '12 galvan steel simpson strong-ti', 'galvan steel simpson strong-ti 1', 'steel simpson strong-ti 1 1.5', 'simpson strong-ti 1 1.5 3', 'strong-ti 1 1.5 3 0.26', '1 1.5 3 0.26 3'], search_term_length=2, term_title_2gram=0, term_title_3gram=0, term_title_4gram=0, term_title_5gram=0, term_description_2gram=0, term_description_3gram=0, term_description_4gram=0, term_description_5gram=0, term_attributes_2gram=0, term_attributes_3gram=0, term_attributes_4gram=0, term_attributes_5gram=0)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer,StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType,StringType,IntegerType\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "features = [\"term_title_match\", \"term_attr_match\",\"term_descr_match\",\"term_title_dice\",\"term_attr_dice\",\"term_descr_dice\",\"term_title_idfCS\", \"term_attr_idfCS\", \"term_descr_idfCS\"]\n",
    "\n",
    "assember_features = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "data = assember_features.transform(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|term_description_5gram|\n",
      "+----------------------+\n",
      "|0                     |\n",
      "|0                     |\n",
      "|0                     |\n",
      "+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp.select(\"term_description_5gram\").show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[term_description_5gram: int]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.select(\"term_description_5gram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------------------------------------------------------------------------------------------------+\n",
      "|id |uid   |features                                                                                           |\n",
      "+---+------+---------------------------------------------------------------------------------------------------+\n",
      "|2  |100001|[2.0,1.0,3.0,0.3333333333333333,0.0,0.0,0.7109604509799033,0.5010182036373578,0.3850999386018893]  |\n",
      "|3  |100001|[1.0,12.0,16.0,0.0,0.0,0.0,0.4442547693388415,0.4024369606020151,0.2140468853236035]               |\n",
      "|9  |100002|[2.0,3.0,5.0,0.0,0.0,0.017857142857142856,0.5860035067962868,0.4011036658482023,0.4539311687927065]|\n",
      "+---+------+---------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+---+---+--------+\n",
      "|id |uid|features|\n",
      "+---+---+--------+\n",
      "+---+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.registerTempTable(\"data\")\n",
    "trainData = sql_sc.sql(\"SELECT * from data where score is not NULL\")\n",
    "testData = sql_sc.sql(\"SELECT * from data where score is NULL\")\n",
    "trainData.select(\"id\",\"uid\",\"features\").show(3,truncate=False)\n",
    "testData.select(\"id\",\"uid\",\"features\").show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(trainD, validD) = trainData.randomSplit([0.8, 0.2])\n",
    "#featureIndexer =VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=5).fit(trainD)\n",
    "rf = RandomForestRegressor(featuresCol=\"features\",labelCol='score', numTrees=11,maxDepth=5)\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "model = pipeline.fit(trainD)\n",
    "predictions = model.transform(validD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.506655\n",
      "Mean Squared Error (MSE) on test data = 0.2567\n",
      "R^2 metric (R2) on test data = 0.0950811\n",
      "Mean Absolute Error (MAE) on test data = 0.416563\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"score\",predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions,{evaluator.metricName:\"rmse\"})\n",
    "mse = evaluator.evaluate(predictions,{evaluator.metricName:\"mse\"})\n",
    "r2 = evaluator.evaluate(predictions,{evaluator.metricName:\"r2\"})\n",
    "mae = evaluator.evaluate(predictions,{evaluator.metricName:\"mae\"})\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "print(\"Mean Squared Error (MSE) on test data = %g\" % mse)\n",
    "print(\"R^2 metric (R2) on test data = %g\" % r2)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
